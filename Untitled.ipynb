{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2358b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "import json\n",
    "from helper import *\n",
    "from config import config\n",
    "from dataloader import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd4e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 8092 \n",
      "Example description ['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .', 'A little girl climbing into a wooden playhouse .', 'A little girl climbing the stairs to her playhouse .', 'A little girl in a pink dress going into a wooden cabin .']\n",
      "Original Vocabulary Size: 8775\n",
      "Save descriptions in separate file\n",
      "Train dataset loaded: 6000\n",
      "Descriptions: train=6000\n",
      "Photos: train=6000\n",
      "Number of training captions  30000\n",
      "preprocessed words 7589 -> 1654\n",
      "Vocab size:  1655\n",
      "Description Length: 37\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from config import config_coco14\n",
    "data = DataLoader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9e66a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 37)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 37, 199)      329345      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 37, 199)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          466944      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1655)         425335      dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,811,960\n",
      "Trainable params: 1,811,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=ModelImpl(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c02d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8f706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07d8cb257144049b627e5f6e94d354d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10675, 'reflen': 10353, 'guess': [10675, 9675, 8675, 7675], 'correct': [5571, 2098, 756, 268]}\n",
      "ratio: 1.0311020960107184\n",
      "Bleu_1: 0.522\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.174\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.401\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing WMD score...\n",
      "WMD: 0.113\n",
      "{'Bleu_1': 0.5218735362997169, 'Bleu_2': 0.3364030250483394, 'Bleu_3': 0.2144490034105726, 'Bleu_4': 0.136225097280134, 'METEOR': 0.17361888826542538, 'ROUGE_L': 0.40110977837933354, 'CIDEr': 0.3237705600045358, 'SPICE': 0.1085759399471379, 'WMD': 0.11270755509661495}\n"
     ]
    }
   ],
   "source": [
    "model.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77810906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
