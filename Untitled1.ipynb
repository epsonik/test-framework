{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae5aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "import json\n",
    "from helper import *\n",
    "from config import config_coco14\n",
    "from dataloader import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82aea27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['startseq a little boy and a woman dancing endseq', 'startseq a man in a dance studio holds the hand of a boy teaching him to dance endseq', 'startseq group of people teach a little boy in a red shirt and sneakers how to dance endseq', 'startseq the little boy in the red shirt is dancing with the lady in the brown shirt and blue jeans while two people look on endseq', 'startseq two adults dancing with a little boy while another person standing in the background endseq']\n"
     ]
    }
   ],
   "source": [
    "def load_doc(filename):\n",
    "\tfile = open(filename, 'r')\n",
    "\ttext = file.read()\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "def load_set(filename):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdataset = list()\n",
    "\t# process line by line\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# skip empty lines\n",
    "\t\tif len(line) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\t# get the image identifier\n",
    "\t\tidentifier = line.split('.')[0]\n",
    "\t\tdataset.append(identifier)\n",
    "\treturn set(dataset)\n",
    "\n",
    "\n",
    "\n",
    "filename = config[\"train_path\"]\n",
    "train = load_set(filename)\n",
    "train_descriptions = load_clean_descriptions(config[\"preprocessed_descriptions_save_path\"], train)\n",
    "print(train_descriptions['3609027309_af75f773d9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32f80b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_descriptions(filename):\n",
    "    imgs = json.load(open(filename, 'r'))\n",
    "    imgs = imgs['images']\n",
    "    descriptions = dict()\n",
    "    for img in imgs:\n",
    "        image_filename= img['filename']\n",
    "        # create list\n",
    "        if image_filename not in descriptions:\n",
    "            descriptions[image_filename] = list()\n",
    "        for sent in img['sentences']:\n",
    "            # wrap descriion in tokens\n",
    "            desc = 'startseq ' + \" \".join(sent['tokens']) + ' endseq'\n",
    "            # store\n",
    "            descriptions[image_filename].append(desc)\n",
    "    return descriptions\n",
    "def all_train_captions(train_descriptions):\n",
    "    # Create a list of all the training captions\n",
    "    all_train_captions = []\n",
    "    for key, val in train_descriptions.items():\n",
    "        for cap in val:\n",
    "            all_train_captions.append(cap)\n",
    "    return all_train_captions\n",
    "\n",
    "def max_length(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    return max(len(d.split()) for d in lines)\n",
    "\n",
    "def to_lines(descriptions):\n",
    "\tall_desc = list()\n",
    "\tfor key in descriptions.keys():\n",
    "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
    "\treturn all_desc\n",
    "\n",
    "def count_words_and_threshold(all_train_captions):\n",
    "    word_count_threshold = 10\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in all_train_captions:\n",
    "        nsents += 1\n",
    "        for w in sent.split(' '):\n",
    "            word_counts[w] = word_counts.get(w, 0) + 1\n",
    "    # Consider only words which occur at least 10 times in the corpus\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))\n",
    "    return vocab   \n",
    "\n",
    "def ixtowordandbackward(vocab):\n",
    "    ixtoword = {}\n",
    "    wordtoix = {}\n",
    "\n",
    "    ix = 1\n",
    "    for w in vocab:\n",
    "        wordtoix[w] = ix\n",
    "        ixtoword[ix] = w\n",
    "        ix += 1\n",
    "    return ixtoword, wordtoix\n",
    "filename='/home2/data/images/coco2014/karpathy/dataset_coco.json'\n",
    "\n",
    "train_descriptions = load_clean_descriptions(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "738b61f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions: train=123287\n",
      "Number of training captions  616767\n",
      "Description Length: 51\n",
      "preprocessed words 27931 -> 7549\n",
      "Vocab size:  7550\n"
     ]
    }
   ],
   "source": [
    "print('Descriptions: train=%d' % len(train_descriptions))\n",
    "all_train_captions = all_train_captions(train_descriptions)\n",
    "print(\"Number of training captions \", len(all_train_captions))\n",
    "# determine the maximum sequence length\n",
    "max_length = max_length(train_descriptions)\n",
    "print('Description Length: %d' % max_length)\n",
    "# Count words and consider only words which occur at least 10 times in the corpus\n",
    "vocab= count_words_and_threshold(all_train_captions)\n",
    "ixtoword, wordtoix = ixtowordandbackward(vocab)\n",
    "vocab_size = len(ixtoword) + 1 # one for appended 0's\n",
    "print(\"Vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14a49d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['startseq a   w o m a n   i n   a   r o o m   w i t h   a   c a t endseq', 'startseq a   g i r l   s m i l e s   a s   s h e   h o l d s   a   c a t   a n d   w e a r s   a   b r i g h t l y   c o l o r e d   s k i r t endseq', 'startseq a   w o m a n   i s   h o l d i n g   a   c a t   i n   h e r   k i t c h e n endseq', 'startseq a   w o m a n   i s   w o r k i n g   i n   a   k i t c h e n   c a r r y i n g   a   s o f t   t o y endseq', 'startseq a   w o m a n   i s   h o l d i n g   a   c a t   i n   h e r   k i t c h e n endseq']\n"
     ]
    }
   ],
   "source": [
    "print(descriptions['COCO_val2014_000000574769.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91032f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# za≈Çaduj opisy\n",
    "self.doc = load_doc(self.config[\"token_path\"])\n",
    "# parse descriptions\n",
    "self.descriptions = load_descriptions(self.doc)\n",
    "print('Loaded: %d ' % len(self.descriptions))\n",
    "print('Example description',self.descriptions[\"1000268201_693b08cb0e\"])\n",
    "\n",
    "clean_descriptions(self.descriptions, self.config)\n",
    "# summarize vocabulary\n",
    "self.vocabulary = to_vocabulary(self.descriptions)\n",
    "print('Original Vocabulary Size: %d' % len(self.vocabulary))\n",
    "print(\"Save descriptions in separate file\")\n",
    "save_descriptions(self.descriptions, self.config[\"preprocessed_descriptions_save_path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
