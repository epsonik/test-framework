{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2358b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "import json\n",
    "from helper import *\n",
    "from config import *\n",
    "from dataloader import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd4e618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset\n",
      "Train dataset loaded: 28999\n",
      "Photos: train=29000\n",
      "Loaded: 31779 \n",
      "Original Vocabulary Size: 47389\n",
      "Save descriptions in separate file\n",
      "Descriptions: train=28999\n",
      "Number of training captions  144995\n",
      "Description Length: 63\n",
      "preprocessed words 45720 -> 8595\n",
      "Vocab size:  8546\n",
      "Found 1926321 word vectors.\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(config_flickr30k_polish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9e66a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 63, 99)       846054      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 63, 99)       0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          364544      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8546)         2196322     dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,997,256\n",
      "Trainable params: 3,997,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=ModelImpl(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900d0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f97fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e260dc642054ae0a848cacfadca5ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2014.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 19929, 'reflen': 18096, 'guess': [19929, 17915, 15901, 13887], 'correct': [7299, 1586, 225, 44]}\n",
      "ratio: 1.101293103448215\n",
      "Bleu_1: 0.366\n",
      "Bleu_2: 0.180\n",
      "Bleu_3: 0.077\n",
      "Bleu_4: 0.035\n",
      "computing METEOR score...\n",
      "METEOR: 0.118\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.285\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.121\n",
      "computing SPICE score...\n",
      "SPICE: 0.020\n",
      "computing WMD score...\n",
      "WMD: 0.499\n",
      "results/flickr30k_polish.json\n",
      "{'Bleu_1': 0.366250188167978, 'Bleu_2': 0.18006616429553668, 'Bleu_3': 0.0771271770313038, 'Bleu_4': 0.03472295177200694, 'METEOR': 0.11755964434833496, 'ROUGE_L': 0.28524205211319414, 'CIDEr': 0.12102050963741637, 'SPICE': 0.01954520463998803, 'WMD': 0.49853663817428756}\n"
     ]
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
