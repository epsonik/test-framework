{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2358b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import *\n",
    "from  config import *\n",
    "from data_processor import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ecdc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataloader2 import *\n",
    "# from  config2 import *\n",
    "# data = DataLoader(config_mixed_flickr8k_8k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd4e618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = DataLoader(config_mixed_flickr8k_flickr8k_n)\n",
    "# print(config_mixed_flickr8k_flickr8k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c1e2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions cleaned.\n",
      "[['a', 'group', 'of', 'people', 'are', 'partying', 'at', 'a', 'masquerade', 'party'], ['a', 'lady', 'in', 'red', 'and', 'black', 'grins', 'at', 'the', 'camera', 'at', 'a', 'costume', 'party'], ['a', 'woman', 'in', 'a', 'domino', 'mask', 'and', 'severe', 'hair', 'is', 'at', 'a', 'party'], ['a', 'woman', 'in', 'a', 'red', 'dress', 'and', 'black', 'mask', 'is', 'on', 'a', 'crowded', 'dance', 'floor'], ['a', 'woman', 'wears', 'a', 'red', 'dress', 'and', 'a', 'black', 'mask', 'while', 'people', 'dance', 'behind', 'her']]\n",
      "Descriptions wraped into start and stop words.\n",
      "['START a child in a pink dress is climbing up a set of stairs in an entry way STOP', 'START a girl going into a wooden building STOP', 'START a little girl climbing into a wooden playhouse STOP', 'START a little girl climbing the stairs to her playhouse STOP', 'START a little girl in a pink dress going into a wooden cabin STOP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 19:09:26.325702: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-06 19:09:26.326178: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed:\n",
      "100\n",
      "Processed:\n",
      "200\n",
      "Processed:\n",
      "300\n",
      "Processed:\n",
      "400\n",
      "Processed:\n",
      "500\n",
      "Processed:\n",
      "600\n",
      "Processed:\n",
      "700\n",
      "Processed:\n",
      "800\n",
      "Processed:\n",
      "900\n",
      "Processed:\n",
      "1000\n",
      "Test images encoded\n",
      "Time taken in seconds = 323.28894209861755\n",
      "Processed:\n",
      "100\n",
      "Processed:\n",
      "200\n",
      "Processed:\n",
      "300\n",
      "Processed:\n",
      "400\n",
      "Processed:\n",
      "500\n",
      "Processed:\n",
      "600\n",
      "Processed:\n",
      "700\n",
      "Processed:\n",
      "800\n",
      "Processed:\n",
      "900\n",
      "Processed:\n",
      "1000\n",
      "Processed:\n",
      "1100\n",
      "Processed:\n",
      "1200\n",
      "Processed:\n",
      "1300\n",
      "Processed:\n",
      "1400\n",
      "Processed:\n",
      "1500\n",
      "Processed:\n",
      "1600\n",
      "Processed:\n",
      "1700\n",
      "Processed:\n",
      "1800\n",
      "Processed:\n",
      "1900\n",
      "Processed:\n",
      "2000\n",
      "Processed:\n",
      "2100\n",
      "Processed:\n",
      "2200\n",
      "Processed:\n",
      "2300\n",
      "Processed:\n",
      "2400\n",
      "Processed:\n",
      "2500\n",
      "Processed:\n",
      "2600\n",
      "Processed:\n",
      "2700\n",
      "Processed:\n",
      "2800\n",
      "Processed:\n",
      "2900\n",
      "Processed:\n",
      "3000\n",
      "Processed:\n",
      "3100\n",
      "Processed:\n",
      "3200\n",
      "Processed:\n",
      "3300\n",
      "Processed:\n",
      "3400\n",
      "Processed:\n",
      "3500\n",
      "Processed:\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a67206",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.test[\"train_images_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.train[\"test_images_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344499cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.test[\"train_images_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.train[\"train_images_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ccfb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.test[\"all_captions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train[\"all_captions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.test[\"train_captions_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.train[\"train_captions_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bdc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.test[\"test_captions_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51404dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.train[\"test_captions_mapping_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelImpl(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_report(data.config[\"results_directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cdf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9aad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}