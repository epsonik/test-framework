{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2358b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import *\n",
    "from  config import *\n",
    "from data_processor import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd4e618",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Loading train dataset\n",
      "Loading images splits\n",
      "Images splits loaded\n",
      "Number of train images:  6000\n",
      "Number of test images:  1000\n",
      "Loading all captions\n",
      "All captions loaded\n",
      "Nuber of all captions:  8091\n",
      "Loading captions splits\n",
      "Captions splits loaded\n",
      "Number of train captions:  6000\n",
      "Number of test test:  1000\n",
      "Loading test dataset\n",
      "Loading images splits\n",
      "Images splits loaded\n",
      "Number of train images:  6000\n",
      "Number of test images:  1000\n",
      "Loading all captions\n",
      "All captions loaded\n",
      "Nuber of all captions:  8091\n",
      "Loading captions splits\n",
      "Captions splits loaded\n",
      "Number of train captions:  6000\n",
      "Number of test test:  1000\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(config_mixed_flickr8k_flickr8k_polish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bd7aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images:  6000\n",
      "Number of test images:  1000\n",
      "Number of train captions:  6000\n",
      "Number of test captions:  1000\n",
      "Descriptions cleaned.\n",
      "[['grupa', 'człowiek', 'imprezować', 'na', 'impreza', 'maskaradowy'], ['Dam', 'w', 'czerwonoczarnych', 'barwy', 'uśmiechać', 'się', 'do', 'kamera', 'na', 'impreza', 'kostiumowy'], ['kobieta', 'w', 'maska', 'domina', 'i', 'ostry', 'włos', 'być', 'na', 'impreza'], ['kobieta', 'w', 'czerwony', 'sukienka', 'i', 'czarny', 'maska', 'być', 'na', 'zatłoczonym', 'parkiet'], ['kobieta', 'nosić', 'czerwony', 'sukienka', 'i', 'czarny', 'maska', 'podczas', 'gdy', 'lud', 'tańczyć', 'za', 'on']]\n",
      "Descriptions wraped into start and stop words.\n",
      "['START dziecko w różowy sukienka wspinać się po schód w sposób wejściowy STOP', 'START dziewczyna wchodzić do drewniany budynek STOP', 'START mały dziewczynka wspinać się do drewniany domek do zabawa STOP', 'START mały dziewczynka wspinać się po schód do swój domek zabawa STOP', 'START mały dziewczynka w różowy sukienka wchodzić do drewniany kabina STOP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 14:00:41.107951: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-11 14:00:41.108550: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded images loaded from: \n",
      "./mixed_flickr8k_flickr8k_polish/Pickle/encoded_train_images.pkl\n",
      "Encoded images loaded from: \n",
      "./mixed_flickr8k_flickr8k_polish/Pickle/encoded_train_images.pkl\n",
      "Number of training captions  30000\n",
      "Description Length: 29\n",
      "preprocessed words 7402 -> 1548\n",
      "Vocab size:  1549\n",
      "Found 1926321 word vectors.\n"
     ]
    }
   ],
   "source": [
    "data=preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c1e2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a67206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, \\\n",
    "    Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import callbacks\n",
    "from eval_utils import calculate_results, prepare_for_evaluation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from numpy import array\n",
    "import pickle\n",
    "from eval_utils import generate_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d4fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 29)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 29, 99)       153351      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 29, 99)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          364544      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1549)         398093      dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,506,324\n",
      "Trainable params: 1,506,324\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def data_generator(descriptions, photos, wordtoix, max_length, num_photos_per_batch, vocab_size):\n",
    "    \"\"\"\n",
    "    Data generator, that serves the data to the model during training\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptions: str\n",
    "        Dictionary where key is image id and value is a list of preprocessed descriptions\n",
    "    photos\n",
    "        Dictionary with encoded images(vector of image features extracted by specified image feature extractor\n",
    "         fe. Inception), identified by image id\n",
    "    wordtoix\n",
    "        Dictionary with keys-words , values -id of word\n",
    "    max_length\n",
    "        Max number of words in caption on dataset\n",
    "    num_photos_per_batch: int\n",
    "    vocab_size: int\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    # loop for ever over images\n",
    "    while 1:\n",
    "        for key, desc_list in descriptions.items():\n",
    "            n += 1\n",
    "            # retrieve the photo feature from the dictionary\n",
    "            photo = photos[key]\n",
    "            for desc in desc_list:\n",
    "                # encode the sentence by translating it to the number representation,\n",
    "                # with the dictionary of words created in in the previous stage\n",
    "                seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n",
    "                # split one sequence into multiple X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pair\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    # store\n",
    "                    X1.append(photo)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            # yield the batch data\n",
    "            if n == num_photos_per_batch:\n",
    "                yield ([array(X1), array(X2)], array(y))\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0\n",
    "\n",
    "class ModelImpl:\n",
    "    def __init__(self, data):\n",
    "        self.data=data\n",
    "        inputs1 = Input(shape=(2048,))\n",
    "        fe1 = Dropout(0.5)(inputs1)\n",
    "        fe2 = Dense(256, activation='relu')(fe1)\n",
    "        inputs2 = Input(shape=(self.data.max_length,))\n",
    "        se1 = Embedding(self.data.vocab_size, general[self.data.language][\"embedings_dim\"], mask_zero=True)(inputs2)\n",
    "        se2 = Dropout(0.5)(se1)\n",
    "        se3 = LSTM(256)(se2)\n",
    "        decoder1 = add([fe2, se3])\n",
    "        decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "        outputs = Dense(self.data.vocab_size, activation='softmax')(decoder2)\n",
    "        self.model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "        self.model.summary()\n",
    "        self.model.layers[2]\n",
    "\n",
    "        self.model.layers[2].set_weights([self.data.embedding_matrix])\n",
    "        self.model.layers[2].trainable = False\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=self.optimizer())\n",
    "        self.setup()\n",
    "\n",
    "    def optimizer(self):\n",
    "        return Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    def setup(self):\n",
    "        # model.optimizer.lr = 0.001\n",
    "        self.epochs = 2\n",
    "        self.number_pics_per_bath = 100\n",
    "        self.steps = len(self.data.train_captions_wrapped) // self.number_pics_per_bath\n",
    "\n",
    "    def train(self):\n",
    "        model_weights_path=\"./\" + self.data.configuration[\"data_name\"] + self.data.configuration[\"model_save_dir\"]\n",
    "        if self.data.configuration[\"train_model\"]:\n",
    "            callback = callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=3)\n",
    "            generator = data_generator(self.data.train_captions_wrapped,\n",
    "                                       self.data.encoded_images_train,\n",
    "                                       self.data.wordtoix,\n",
    "                                       self.data.max_length,\n",
    "                                       self.number_pics_per_bath,\n",
    "                                       self.data.vocab_size)\n",
    "            self.model.fit(generator, epochs=self.epochs,\n",
    "                           steps_per_epoch=self.steps,\n",
    "                           callbacks=[callback],\n",
    "                           verbose=1)\n",
    "            if self.data.configuration[\"save_model\"]:\n",
    "                writepath = model_weights_path+ \"/\"+'model' + '.h5'\n",
    "                self.model.save(writepath)\n",
    "                self.model.save_weights(model_weights_path\n",
    "                                        + self.data.configuration[\"model_save_path\"])\n",
    "        else:\n",
    "            self.model.load_weights(model_weights_path\n",
    "                                        +self.data.configuration[\"model_save_path\"])\n",
    "\n",
    "    def evaluate(self):\n",
    "        expected, results = prepare_for_evaluation(self.data.encoded_images_test, self.data.test_captions_mapping,\n",
    "                                                   self.data.wordtoix, self.data.ixtoword, self.data.max_length,\n",
    "                                                   self.model)\n",
    "        out = calculate_results(expected, results, self.data.configuration)\n",
    "        print(out)\n",
    "\n",
    "model=ModelImpl(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c9aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60/60 [==============================] - 278s 5s/step - loss: 5.2461\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 279s 5s/step - loss: 4.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateuszb/opt/anaconda3/envs/framework/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4945ee14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for evaluation\n",
      "Processed:\n",
      "0\n",
      "Processed:\n",
      "100\n",
      "Processed:\n",
      "200\n",
      "Processed:\n",
      "300\n",
      "Processed:\n",
      "400\n",
      "Processed:\n",
      "500\n",
      "Processed:\n",
      "600\n",
      "Processed:\n",
      "700\n",
      "Processed:\n",
      "800\n",
      "Processed:\n",
      "900\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 47541 tokens at 225714.65 tokens per second.\n",
      "PTBTokenizer tokenized 18492 tokens at 148423.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 17493, 'reflen': 9385, 'guess': [17493, 16493, 15493, 14493], 'correct': [2111, 247, 5, 0]}\n",
      "ratio: 1.863931806073323\n",
      "Bleu_1: 0.121\n",
      "Bleu_2: 0.043\n",
      "Bleu_3: 0.008\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.075\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.175\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.018\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/Users/mateuszb/PycharmProjects/test-framework/coco-caption/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [35.89 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [33.360 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 1.312 min\n",
      "SPICE: 0.008\n",
      "computing WMD score...\n",
      "WMD: 0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bleu_1': 0.1206768421654307, 'Bleu_2': 0.04251190981231438, 'Bleu_3': 0.008355104862535927, 'Bleu_4': 4.4789308317568335e-07, 'METEOR': 0.07455188805687833, 'ROUGE_L': 0.17485580166212816, 'CIDEr': 0.01835006663880602, 'SPICE': 0.00758000691216313, 'WMD': 0.6973705129993766}\n"
     ]
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e82d24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final results saved to final_results.csv\n"
     ]
    }
   ],
   "source": [
    "generate_report(general[\"results_directory\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb6c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17390a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677e230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}