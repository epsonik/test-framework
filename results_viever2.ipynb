{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"./coco-caption\")\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "from dataloader import get_dataset_configuration, load_all_captions_flickr, load_all_captions_coco\n",
    "import glob\n",
    "from IPython.display import display, clear_output\n",
    "from collections import deque\n",
    "from ipywidgets import HBox, Output, Button\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "from config import general\n",
    "intersection=dict()\n",
    "max_set_of_ids=set()\n",
    "max_dict_of_ids=list()\n",
    "min_dict_of_ids=list()\n",
    "min_set_of_ids=set()\n",
    "\n",
    "bleu1_ids=list()\n",
    "bleu2_ids=list()\n",
    "bleu3_ids=list()\n",
    "bleu4_ids=list()\n",
    "cider_ids=list()\n",
    "meteor_ids=list()\n",
    "rouge_ids=list()\n",
    "for result_config_name in os.listdir(general[\"results_directory\"]):\n",
    "    if result_config_name.endswith(\".json\"):\n",
    "        results = json.load(open(\"./\" + general[\"results_directory\"] + \"/\" + result_config_name, 'r'))\n",
    "        dataset_name=results[\"dataset_name\"]\n",
    "        result_images_ids = list(results['imgToEval'].keys())\n",
    "        bleu1=dict()\n",
    "        bleu2=dict()\n",
    "        bleu3=dict()\n",
    "        bleu4=dict()\n",
    "        rouge=dict()\n",
    "        meteor=dict()\n",
    "        cider=dict()\n",
    "        for img_id in result_images_ids:\n",
    "            bleu1[img_id]=results['imgToEval'][img_id]['Bleu_1']\n",
    "            bleu2[img_id]=results['imgToEval'][img_id]['Bleu_2']\n",
    "            bleu3[img_id]=results['imgToEval'][img_id]['Bleu_3']\n",
    "            bleu4[img_id]=results['imgToEval'][img_id]['Bleu_4']\n",
    "            rouge[img_id]=results['imgToEval'][img_id]['ROUGE_L']\n",
    "            meteor[img_id]=results['imgToEval'][img_id]['METEOR']\n",
    "            cider[img_id]=results['imgToEval'][img_id]['CIDEr']\n",
    "\n",
    "        def sort_and_get_max_min(metric, name):\n",
    "            sorted_by=sorted(metric.items(), key=lambda x:x[1])\n",
    "            sorted_max_n=sorted_by[1]\n",
    "            image_id_max=sorted_max_n[0]\n",
    "            image_id_min=sorted_max_n[0]\n",
    "            min_set_of_ids.append(image_id_min)\n",
    "            if image_id_min not in min_dict_of_ids:\n",
    "                if min_dict_of_ids[image_id_min][\"measures\"]:\n",
    "                    a=min_dict_of_ids[image_id_min][\"measures\"]\n",
    "                    b=a.append(name)\n",
    "                    min_dict_of_ids[image_id_min][\"measures\"]=b\n",
    "                else:\n",
    "                    min_dict_of_ids[image_id_min]={\"measures\":[name]}\n",
    "            max_set_of_ids.append(image_id_max)\n",
    "            if image_id_max not in max_dict_of_ids:\n",
    "                if max_dict_of_ids[image_id_min][\"measures\"]:\n",
    "                    a=max_dict_of_ids[image_id_min][\"measures\"]\n",
    "                    b=a.append(name)\n",
    "                    max_dict_of_ids[image_id_max][\"measures\"]=b\n",
    "                else:\n",
    "                    max_dict_of_ids[image_id_max]={\"measures\":[name]}\n",
    "            return image_id_max,image_id_min, sorted_by\n",
    "\n",
    "        bleu1_sorted_max_n, bleu1_sorted_min_n, bleu1_sorted=sort_and_get_max_min(bleu1)\n",
    "        bleu1_ids.append(bleu1_sorted_max_n)\n",
    "        bleu1_ids.append(bleu1_sorted_min_n)\n",
    "        bleu2_sorted_max_n, bleu2_sorted_min_n, bleu2_sorted=sort_and_get_max_min(bleu2)\n",
    "        bleu2_ids.append(bleu2_sorted_max_n)\n",
    "        bleu2_ids.append(bleu2_sorted_min_n)\n",
    "        bleu3_sorted_max_n, bleu3_sorted_min_n, bleu3_sorted=sort_and_get_max_min(bleu3)\n",
    "        bleu3_ids.append(bleu3_sorted_max_n)\n",
    "        bleu3_ids.append(bleu3_sorted_min_n)\n",
    "        bleu4_sorted_max_n, bleu4_sorted_min_n, bleu4_sorted=sort_and_get_max_min(bleu4)\n",
    "        bleu4_ids.append(bleu4_sorted_max_n)\n",
    "        bleu1_ids.append(bleu4_sorted_min_n)\n",
    "        meteor_sorted_max_n, meteor_sorted_min_n, meteor_sorted=sort_and_get_max_min(meteor)\n",
    "        meteor_ids.append(meteor_sorted_max_n)\n",
    "        meteor_ids.append(meteor_sorted_min_n)\n",
    "        rouge_sorted_max_n, rouge_sorted_min_n, rouge_sorted=sort_and_get_max_min(rouge)\n",
    "        rouge_ids.append(rouge_sorted_max_n)\n",
    "        rouge_ids.append(rouge_sorted_min_n)\n",
    "        cider_sorted_max_n, cider_sorted_min_n, cider_sorted=sort_and_get_max_min(cider)\n",
    "        cider_ids.append(cider_sorted_max_n)\n",
    "        cider_ids.append(cider_sorted_min_n)\n",
    "\n",
    "        intersection_max={'Bleu_1':bleu1_sorted_max_n,'Bleu_2':bleu2_sorted_max_n, 'Bleu_3':bleu3_sorted_max_n,\n",
    "                          'Bleu_4':bleu4_sorted_max_n, 'ROUGE_L':rouge_sorted_max_n, 'METEOR':meteor_sorted_max_n,\n",
    "                          'CIDEr':cider_sorted_max_n}\n",
    "        intersection_min={'Bleu_1':bleu1_sorted_min_n,'Bleu_2':bleu2_sorted_min_n, 'Bleu_3':bleu3_sorted_min_n,\n",
    "                          'Bleu_4':bleu4_sorted_min_n, 'ROUGE_L':rouge_sorted_min_n, 'METEOR':meteor_sorted_min_n,\n",
    "                          'CIDEr':cider_sorted_min_n}\n",
    "\n",
    "        print(intersection_max)\n",
    "        print(len(intersection_min))\n",
    "        print(\"...........................\")\n",
    "        intersection[result_config_name]={\"max_n\":intersection_max, \"min_n\":intersection_min, \"dataset_name\":dataset_name}\n",
    "\n",
    "        # image_results = info['imgToEval'][image_id]\n",
    "        # show_image_results_captions(image_id)\n",
    "\n",
    "with open(\"./\" + general[\"results_directory\"] +\"/intersection\"+ \"/intersection_results.json\", 'w') as outfile:\n",
    "    json.dump(\n",
    "        {'intersection': intersection, \"max_list_of_ids\":max_list_of_ids, \"min_list_of_ids\":min_list_of_ids,\"bleu1_ids\":bleu1_ids,\n",
    "         \"bleu2_ids\":bleu2_ids,\n",
    "         \"bleu3_ids\":bleu3_ids,\n",
    "         \"bleu4_ids\":bleu4_ids,\n",
    "         \"cider_ids\":cider_ids,\n",
    "         \"meteor_ids\":meteor_ids,\n",
    "         \"rouge_ids\":rouge_ids},outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_flickr(images_dir):\n",
    "    \"\"\"\n",
    "    Method to map images ids to pictures for data in Flickr structure\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images_dir: str\n",
    "        Path to the directory with all images from  Flickr type dataset\n",
    "    Returns\n",
    "    -------\n",
    "    all_images_mapping: dict->\n",
    "        paths to all images\n",
    "\n",
    "    \"\"\"\n",
    "    # add global paths to the all images in images_dir directory\n",
    "    all_images = glob.glob(images_dir + '*.jpg')\n",
    "    all_images_mapping = dict()\n",
    "    for i in all_images:  # img is list of full path names of all images\n",
    "        image_name = i.split(\"/\")[-1]\n",
    "        image_id = image_name.split(\".\")[0]\n",
    "        all_images_mapping[image_id] = i  # Add it to the dict of train images\n",
    "    return all_images_mapping\n",
    "\n",
    "def load_images_coco(configuration):\n",
    "    \"\"\"\n",
    "    Method to map images ids to pictures for data in COCO structure\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    configuration\n",
    "        Configuration of the dataset, with paths to the images and\n",
    "         datasets specific files like file that mapps images with image id\n",
    "    Returns\n",
    "    -------\n",
    "    all_images_mapping: dict->\n",
    "        paths to all images from coco type data identidied by image ids\n",
    "\n",
    "    \"\"\"\n",
    "    file_with_images_def = configuration[\"images_names_file_path\"]\n",
    "    images_folder = configuration[\"images_dir\"]\n",
    "    info = json.load(open(file_with_images_def))\n",
    "    all_images_mapping = dict()\n",
    "    for ix in range(len(info['images'])):\n",
    "        img = info['images'][ix]\n",
    "        image_filename = img['file_path'].rsplit(\".\", 1)[0]\n",
    "        #create global path to the image by users directory\n",
    "        file_path = images_folder + \"/\" + img['file_path']\n",
    "\n",
    "        if image_filename.find(\"/\") != -1:\n",
    "            image_filename = img['file_path'].rsplit(\"/\", 1)[1].rsplit(\".\", 1)[0]\n",
    "        #define data splits\n",
    "        if img['split'] in ['train','val', 'test', 'restval']:\n",
    "            all_images_mapping[image_filename] = file_path\n",
    "\n",
    "    return all_images_mapping\n",
    "\n",
    "def get_images_for_split(dataset_name):\n",
    "    # Load dataset configuration, by the name of the dataset assigned for training/testing\n",
    "    train_dataset_configuration = get_dataset_configuration(dataset_name)\n",
    "    # Therefore Flickr and COCO have different file and data structures, to show captions and split of data\n",
    "    # different methods for loading captions and images are used.\n",
    "    # Datasets Flickr30k, COCO2017, COCO2014 have the same strucutre of files with captions and split informations.\n",
    "    if train_dataset_configuration[\"data_name\"] in [\"flickr30k\", \"coco17\", \"coco14\"]:\n",
    "        all_images = load_images_coco(train_dataset_configuration)\n",
    "    # Datasets Flickr30k, Flickr8k_polish, AIDe, Flickr8k  have the same strucutre of files with captions and split informations.\n",
    "    if train_dataset_configuration[\"data_name\"] in [\"flickr30k_polish\", \"flickr8k_polish\", \"aide\", \"flickr8k\"]:\n",
    "        all_images = load_images_flickr(train_dataset_configuration[\"images_dir\"])\n",
    "    return all_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mixed_flickr8k_8k_n.json', 'mixed_coco2014_coco2014.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a452cc47f0420999d28a38a86e3fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Name of the dataset:', options=('mixed_flickr8k_8k_n.json', 'mixed_coco2014_coco2014.json'â€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def show_image_results_captions(image_id, dataset_name, result_config_name):\n",
    "    \"\"\"\n",
    "    Method to show image, ground truth captions, predicted caption and results of metrics\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_id: str\n",
    "        ID of image\n",
    "    Returns\n",
    "    -------\n",
    "    Prints image, ground truth captions, predicted caption and results of metrics\n",
    "    \"\"\"\n",
    "    all_images_from_split = get_images_for_split(dataset_name)\n",
    "    #Load results of metrics from file\n",
    "    results_info = json.load(open(\"./\" + general[\"results_directory\"] + \"/\" + result_config_name, 'r'))\n",
    "    image_results = results_info['imgToEval'][image_id]\n",
    "    print('Dataset name: {}'.format(dataset_name))\n",
    "    #Load image\n",
    "    I = io.imread(all_images_from_split[image_id])\n",
    "    plt.imshow(I)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"Ground truth captions\")\n",
    "    print(image_results['ground_truth_captions'])\n",
    "    print(\"Predicted captions\")\n",
    "    print(image_results['caption'])\n",
    "    #Display results in pretty table\n",
    "    print( f'\\n===== Results =====' )\n",
    "    t = PrettyTable((\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"))\n",
    "    t.add_row((image_results[\"Bleu_1\"], image_results[\"Bleu_2\"], image_results[\"Bleu_3\"], image_results[\"Bleu_4\"]))\n",
    "    t2 = PrettyTable((\"METEOR\", \"ROUGE_L\", \"CIDEr\", \"WMD\"))\n",
    "    t2.add_row((image_results[\"METEOR\"],image_results[\"ROUGE_L\"], image_results[\"CIDEr\"], image_results[\"WMD\"]))\n",
    "    print(t)\n",
    "    print(t2)\n",
    "    print()\n",
    "\n",
    "intersection_results = json.load(open(\"./\" + general[\"results_directory\"] + \"/intersection_results.json\"))\n",
    "config_names=list(intersection_results['intersection'].keys())\n",
    "type_of=\"max_n\"\n",
    "for config in config_names:\n",
    "    b=config[type_of][\"BLeu_4\"]\n",
    "    dataset_name=config[dataset_name]\n",
    "    show_image_results_captions(b, dataset_name, config)\n",
    "    m=config[type_of][\"METEOR\"]\n",
    "    r=config[type_of][\"ROUGE_L\"]\n",
    "    c=config[type_of][\"CIDEr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create fancy viever for images, captions and results of evaluation\n",
    "d=deque(images_ids)\n",
    "#Button to read image back\n",
    "left = Button(description=\"<\")\n",
    "#Button to read next image\n",
    "right = Button(description=\">\")\n",
    "\n",
    "switch = [left, right]\n",
    "\n",
    "combined = HBox([items for items in switch])\n",
    "out = Output()\n",
    "\n",
    "def on_button_left(ex):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        d.rotate(1)\n",
    "        show_image_results_captions(d[0])\n",
    "def on_button_right(ex):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        d.rotate(-1)\n",
    "        show_image_results_captions(d[0])\n",
    "l=switch[0].on_click(on_button_left)\n",
    "r=switch[1].on_click(on_button_right)\n",
    "display(combined)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}