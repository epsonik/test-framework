{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"./coco-caption\")\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "from dataloader import get_dataset_configuration, load_all_captions_flickr, load_all_captions_coco\n",
    "import glob\n",
    "from IPython.display import display, clear_output\n",
    "from collections import deque\n",
    "from ipywidgets import HBox, Output, Button, widgets\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_images_flickr(images_dir):\n",
    "    \"\"\"\n",
    "    Method to map images ids to pictures for data in Flickr structure\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images_dir: str\n",
    "        Path to the directory with all images from  Flickr type dataset\n",
    "    Returns\n",
    "    -------\n",
    "    all_images_mapping: dict->\n",
    "        paths to all images\n",
    "\n",
    "    \"\"\"\n",
    "    # add global paths to the all images in images_dir directory\n",
    "    all_images = glob.glob(images_dir + '*.jpg')\n",
    "    all_images_mapping = dict()\n",
    "    for i in all_images:  # img is list of full path names of all images\n",
    "        image_name = i.split(\"/\")[-1]\n",
    "        image_id = image_name.split(\".\")[0]\n",
    "        all_images_mapping[image_id] = i  # Add it to the dict of train images\n",
    "    return all_images_mapping\n",
    "\n",
    "def load_images_coco(configuration):\n",
    "    \"\"\"\n",
    "    Method to map images ids to pictures for data in COCO structure\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    configuration\n",
    "        Configuration of the dataset, with paths to the images and\n",
    "         datasets specific files like file that mapps images with image id\n",
    "    Returns\n",
    "    -------\n",
    "    all_images_mapping: dict->\n",
    "        paths to all images from coco type data identidied by image ids\n",
    "\n",
    "    \"\"\"\n",
    "    file_with_images_def = configuration[\"images_names_file_path\"]\n",
    "    images_folder = configuration[\"images_dir\"]\n",
    "    info = json.load(open(file_with_images_def))\n",
    "    all_images_mapping = dict()\n",
    "    for ix in range(len(info['images'])):\n",
    "        img = info['images'][ix]\n",
    "        image_filename = img['file_path'].rsplit(\".\", 1)[0]\n",
    "        #create global path to the image by users directory\n",
    "        file_path = images_folder + \"/\" + img['file_path']\n",
    "\n",
    "        if image_filename.find(\"/\") != -1:\n",
    "            image_filename = img['file_path'].rsplit(\"/\", 1)[1].rsplit(\".\", 1)[0]\n",
    "        #define data splits\n",
    "        if img['split'] in ['train','val', 'test', 'restval']:\n",
    "            all_images_mapping[image_filename] = file_path\n",
    "\n",
    "    return all_images_mapping\n",
    "\n",
    "def get_images_for_split(dataset_name):\n",
    "    # Load dataset configuration, by the name of the dataset assigned for training/testing\n",
    "    train_dataset_configuration = get_dataset_configuration(dataset_name)\n",
    "    # Therefore Flickr and COCO have different file and data structures, to show captions and split of data\n",
    "    # different methods for loading captions and images are used.\n",
    "    # Datasets Flickr30k, COCO2017, COCO2014 have the same strucutre of files with captions and split informations.\n",
    "    if train_dataset_configuration[\"data_name\"] in [\"flickr30k\", \"coco17\", \"coco14\"]:\n",
    "        all_images = load_images_coco(train_dataset_configuration)\n",
    "    # Datasets Flickr30k, Flickr8k_polish, AIDe, Flickr8k  have the same strucutre of files with captions and split informations.\n",
    "    if train_dataset_configuration[\"data_name\"] in [\"flickr30k_polish\", \"flickr8k_polish\", \"aide\", \"flickr8k\"]:\n",
    "        all_images = load_images_flickr(train_dataset_configuration[\"images_dir\"])\n",
    "    return all_images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from config import general\n",
    "intersection=dict()\n",
    "max_set_of_ids=set()\n",
    "max_dict_of_ids=dict()\n",
    "min_dict_of_ids=dict()\n",
    "min_set_of_ids=set()\n",
    "\n",
    "bleu1_ids=list()\n",
    "bleu2_ids=list()\n",
    "bleu3_ids=list()\n",
    "bleu4_ids=list()\n",
    "cider_ids=list()\n",
    "meteor_ids=list()\n",
    "rouge_ids=list()\n",
    "for result_config_name in os.listdir(general[\"results_directory\"]):\n",
    "    if result_config_name.endswith(\".json\"):\n",
    "        results = json.load(open(\"./\" + general[\"results_directory\"] + \"/\" + result_config_name, 'r'))\n",
    "        dataset_name=results[\"dataset_name\"]\n",
    "\n",
    "        result_images_ids = list(results['imgToEval'].keys())\n",
    "        bleu1=dict()\n",
    "        bleu2=dict()\n",
    "        bleu3=dict()\n",
    "        bleu4=dict()\n",
    "        rouge=dict()\n",
    "        meteor=dict()\n",
    "        cider=dict()\n",
    "        for img_id in result_images_ids:\n",
    "            bleu1[img_id]=results['imgToEval'][img_id]['Bleu_1']\n",
    "            bleu2[img_id]=results['imgToEval'][img_id]['Bleu_2']\n",
    "            bleu3[img_id]=results['imgToEval'][img_id]['Bleu_3']\n",
    "            bleu4[img_id]=results['imgToEval'][img_id]['Bleu_4']\n",
    "            rouge[img_id]=results['imgToEval'][img_id]['ROUGE_L']\n",
    "            meteor[img_id]=results['imgToEval'][img_id]['METEOR']\n",
    "            cider[img_id]=results['imgToEval'][img_id]['CIDEr']\n",
    "\n",
    "        def sort_and_get_max_min(metric, name):\n",
    "            sorted_by=sorted(metric.items(), key=lambda x:x[1])\n",
    "\n",
    "            sorted_max_n=sorted_by[-1]\n",
    "            sorted_min_n=sorted_by[1]\n",
    "\n",
    "            image_id_min=sorted_min_n[0]\n",
    "            image_id_max=sorted_max_n[0]\n",
    "\n",
    "            min_set_of_ids.add(image_id_min)\n",
    "            if image_id_min not in min_dict_of_ids:\n",
    "                min_dict_of_ids[image_id_min]={\"measures\":{name},\n",
    "                                               \"dataset_name\":dataset_name,\n",
    "                                               \"Bleu_1\":results['imgToEval'][image_id_min]['Bleu_1'],\n",
    "                                               \"Bleu_2\":results['imgToEval'][image_id_min]['Bleu_2'],\n",
    "                                                \"Bleu_3\":results['imgToEval'][image_id_min]['Bleu_3'],\n",
    "                                                \"Bleu_4\":results['imgToEval'][image_id_min]['Bleu_4'],\n",
    "                                                \"ROUGE_L\":results['imgToEval'][image_id_min]['ROUGE_L'],\n",
    "                                                \"METEOR\":results['imgToEval'][image_id_min]['METEOR'],\n",
    "                                                \"CIDEr\":results['imgToEval'][image_id_min]['CIDEr'],\n",
    "                                               \"caption\":results['imgToEval'][image_id_min]['caption'],\n",
    "                                               \"ground_truth_captions\":results['imgToEval'][image_id_min]['ground_truth_captions'],\n",
    "                                               \"result_config_name\":result_config_name,\n",
    "                                               \"image_path\":all_images_from_split[image_id_min]}\n",
    "            else:\n",
    "                a=min_dict_of_ids[image_id_min][\"measures\"]\n",
    "                a.add(name)\n",
    "\n",
    "            max_set_of_ids.add(image_id_max)\n",
    "            if image_id_max not in max_dict_of_ids:\n",
    "                max_dict_of_ids[image_id_max]={\"measures\":{name},\n",
    "                                               \"dataset_name\":dataset_name,\n",
    "                                                \"Bleu_1\":results['imgToEval'][image_id_max]['Bleu_1'],\n",
    "                                               \"Bleu_2\":results['imgToEval'][image_id_max]['Bleu_2'],\n",
    "                                                \"Bleu_3\":results['imgToEval'][image_id_max]['Bleu_3'],\n",
    "                                                \"Bleu_4\":results['imgToEval'][image_id_max]['Bleu_4'],\n",
    "                                                \"ROUGE_L\":results['imgToEval'][image_id_max]['ROUGE_L'],\n",
    "                                                \"METEOR\":results['imgToEval'][image_id_max]['METEOR'],\n",
    "                                                \"CIDEr\":results['imgToEval'][image_id_max]['CIDEr'],\n",
    "                                               \"caption\":results['imgToEval'][image_id_max]['caption'],\n",
    "                                               \"ground_truth_captions\":results['imgToEval'][image_id_max]['ground_truth_captions'],\n",
    "                                               \"result_config_name\":result_config_name,\n",
    "                                               \"image_path\":all_images_from_split[image_id_max]}\n",
    "            else:\n",
    "                a=max_dict_of_ids[image_id_max][\"measures\"]\n",
    "                a.add(name)\n",
    "            return image_id_max, image_id_min, sorted_by\n",
    "\n",
    "        all_images_from_split = get_images_for_split(dataset_name)\n",
    "        bleu1_sorted_max_n, bleu1_sorted_min_n, bleu1_sorted=sort_and_get_max_min(bleu1, \"Bleu_1\")\n",
    "        bleu2_sorted_max_n, bleu2_sorted_min_n, bleu2_sorted=sort_and_get_max_min(bleu2, \"Bleu_2\")\n",
    "        bleu3_sorted_max_n, bleu3_sorted_min_n, bleu3_sorted=sort_and_get_max_min(bleu3,'Bleu_3')\n",
    "        bleu4_sorted_max_n, bleu4_sorted_min_n, bleu4_sorted=sort_and_get_max_min(bleu4, 'Bleu_4')\n",
    "        meteor_sorted_max_n, meteor_sorted_min_n, meteor_sorted=sort_and_get_max_min(meteor,'METEOR')\n",
    "        rouge_sorted_max_n, rouge_sorted_min_n, rouge_sorted=sort_and_get_max_min(rouge, 'ROUGE_L')\n",
    "        cider_sorted_max_n, cider_sorted_min_n, cider_sorted=sort_and_get_max_min(cider, 'CIDEr')\n",
    "\n",
    "\n",
    "metrics=['Bleu_4', 'METEOR','ROUGE_L','CIDEr']\n",
    "for x in max_dict_of_ids.keys():\n",
    "    max_dict_of_ids[x][\"is_best\"]=all(item in max_dict_of_ids[x]['measures'] for item in metrics)\n",
    "for x in min_dict_of_ids.keys():\n",
    "    min_dict_of_ids[x][\"is_best\"]=all(item in min_dict_of_ids[x]['measures'] for item in metrics)\n",
    "\n",
    "print(max_dict_of_ids)\n",
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "with open(\"./\" + general[\"results_directory\"] +\"/intersection\"+ \"/intersection_results.json\", 'w') as outfile:\n",
    "    json.dump(\n",
    "        {\"max_dict_of_ids\":max_dict_of_ids,\n",
    "         \"min_dict_of_ids\":min_dict_of_ids},outfile, cls=SetEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mixed_flickr8k_8k_n.json', 'mixed_coco2014_coco2014.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a452cc47f0420999d28a38a86e3fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Name of the dataset:', options=('mixed_flickr8k_8k_n.json', 'mixed_coco2014_coco2014.json'â€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def show_image_results_captions(image_id, intersection_results):\n",
    "    \"\"\"\n",
    "    Method to show image, ground truth captions, predicted caption and results of metrics\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_id: str\n",
    "        ID of image\n",
    "    Returns\n",
    "    -------\n",
    "    Prints image, ground truth captions, predicted caption and results of metrics\n",
    "    \"\"\"\n",
    "    #Load results of metrics from file\n",
    "    image_results = intersection_results[image_id]\n",
    "    print('Dataset name: {}'.format(image_results[\"dataset_name\"]))\n",
    "    #Load image\n",
    "    I = io.imread(image_results['image_path'])\n",
    "    plt.imshow(I)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"Ground truth captions\")\n",
    "    print(image_results['ground_truth_captions'])\n",
    "    print(\"Predicted captions\")\n",
    "    print(image_results['caption'])\n",
    "    #Display results in pretty table\n",
    "    print( f'\\n===== Results =====' )\n",
    "    print(image_results[\"metrics\"])\n",
    "    print(image_results[\"is_best\"])\n",
    "    t = PrettyTable((\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"))\n",
    "    t.add_row((image_results[\"Bleu_1\"], image_results[\"Bleu_2\"], image_results[\"Bleu_3\"], image_results[\"Bleu_4\"]))\n",
    "    t2 = PrettyTable((\"METEOR\", \"ROUGE_L\", \"CIDEr\"))\n",
    "    t2.add_row((image_results[\"METEOR\"],image_results[\"ROUGE_L\"], image_results[\"CIDEr\"]))\n",
    "    print(t)\n",
    "    print(t2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#List all files from results directory to view data\n",
    "type_of_filter = [\"max_dict_of_ids\", \"min_dict_of_ids\"]\n",
    "selectbox = widgets.Select(\n",
    "    options=type_of_filter,\n",
    "    value=type_of_filter[0],\n",
    "    description='Min/max:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(selectbox.value)\n",
    "intersection_results = json.load(open(general[\"results_directory\"] + \"/intersection/intersection_results.json\"))\n",
    "inter_results=intersection_results[selectbox.value]\n",
    "images_ids=list(inter_results.keys())\n",
    "#Create fancy viever for images, captions and results of evaluation\n",
    "d=deque(images_ids)\n",
    "#Button to read image back\n",
    "left = Button(description=\"<\")\n",
    "#Button to read next image\n",
    "right = Button(description=\">\")\n",
    "\n",
    "switch = [left, right]\n",
    "\n",
    "combined = HBox([items for items in switch])\n",
    "out = Output()\n",
    "\n",
    "def on_button_left(ex):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        d.rotate(1)\n",
    "        show_image_results_captions(d[0], inter_results)\n",
    "def on_button_right(ex):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        d.rotate(-1)\n",
    "        show_image_results_captions(d[0], inter_results)\n",
    "l=switch[0].on_click(on_button_left)\n",
    "r=switch[1].on_click(on_button_right)\n",
    "display(combined)\n",
    "display(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}