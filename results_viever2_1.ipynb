{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"./coco-caption\")\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "from dataloader import get_dataset_configuration, load_all_captions_flickr, load_all_captions_coco\n",
    "import glob\n",
    "from IPython.display import display, clear_output\n",
    "from collections import deque\n",
    "from ipywidgets import HBox, Output, Button, widgets\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_images_flickr(dataset_configuration):\n",
    "    \"\"\"\n",
    "    Method to map images ids to pictures for data in Flickr structure\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images_dir: str\n",
    "        Path to the directory with all images from  Flickr type dataset\n",
    "    Returns\n",
    "    -------\n",
    "    all_images_mapping: dict->\n",
    "        paths to all images\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    all_captions = load_all_captions_flickr(dataset_configuration[\"captions_file_path\"])\n",
    "\n",
    "    images_dir = dataset_configuration[\"images_dir\"]\n",
    "    train_images = set(open(dataset_configuration[\n",
    "                    \"train_images_names_file_path\"], 'r').read().strip().split('\\n'))\n",
    "    \n",
    "    \n",
    "    # add global paths to the all images in images_dir directory\n",
    "    all_images = glob.glob(images_dir + '*.jpg')\n",
    "    all_images_mapping = dict()\n",
    "    train_images_mapping = dict()\n",
    "    for i in all_images:  # img is list of full path names of all images\n",
    "        image_name = i.split(\"/\")[-1]\n",
    "        image_id = image_name.split(\".\")[0]\n",
    "        all_images_mapping[image_id] = i \n",
    "        if image_name in train_images and image_id in all_captions.keys():\n",
    "            train_images_mapping[image_id] = all_captions[image_id]\n",
    "    return all_images_mapping, train_images_mapping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_images_coco(configuration):\n",
    "    \"\"\"\n",
    "    Method to map images ids to pictures for data in COCO structure\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    configuration\n",
    "        Configuration of the dataset, with paths to the images and\n",
    "         datasets specific files like file that mapps images with image id\n",
    "    Returns\n",
    "    -------\n",
    "    all_images_mapping: dict->\n",
    "        paths to all images from coco type data identidied by image ids\n",
    "\n",
    "    \"\"\"\n",
    "    all_captions = load_all_captions_coco(configuration[\"captions_file_path\"])\n",
    "    \n",
    "    file_with_images_def = configuration[\"images_names_file_path\"]\n",
    "    images_folder = configuration[\"images_dir\"]\n",
    "    info = json.load(open(file_with_images_def))\n",
    "    all_images_mapping = dict()\n",
    "    train_images_mapping = dict()\n",
    "    for ix in range(len(info['images'])):\n",
    "        img = info['images'][ix]\n",
    "        image_filename = img['file_path'].rsplit(\".\", 1)[0]\n",
    "        #create global path to the image by users directory\n",
    "        file_path = images_folder + \"/\" + img['file_path']\n",
    "\n",
    "        if image_filename.find(\"/\") != -1:\n",
    "            image_filename = img['file_path'].rsplit(\"/\", 1)[1].rsplit(\".\", 1)[0]\n",
    "        #define data splits\n",
    "        if img['split'] in ['train','val', 'test', 'restval']:\n",
    "            all_images_mapping[image_filename] = file_path\n",
    "            print(image_filename)\n",
    "            print(all_captions[image_filename])\n",
    "            if img['split'] == 'train' and image_filename in all_captions.keys():\n",
    "                    train_images_mapping[image_filename] = all_captions[image_filename]\n",
    "            all_images_mapping[image_filename] = file_path\n",
    "\n",
    "    return all_images_mapping, train_images_mapping\n",
    "\n",
    "def get_images_for_split(dataset_name):\n",
    "    # Load dataset configuration, by the name of the dataset assigned for training/testing\n",
    "    train_dataset_configuration = get_dataset_configuration(dataset_name)\n",
    "    # Therefore Flickr and COCO have different file and data structures, to show captions and split of data\n",
    "    # different methods for loading captions and images are used.\n",
    "    # Datasets Flickr30k, COCO2017, COCO2014 have the same strucutre of files with captions and split informations.\n",
    "    if train_dataset_configuration[\"data_name\"] in [\"flickr30k\", \"coco17\", \"coco14\"]:\n",
    "        all_images, train_captions_mapping = load_images_coco(train_dataset_configuration)\n",
    "    # Datasets Flickr30k, Flickr8k_polish, AIDe, Flickr8k  have the same strucutre of files with captions and split informations.\n",
    "    if train_dataset_configuration[\"data_name\"] in [\"flickr30k_polish\", \"flickr8k_polish\", \"aide\", \"flickr8k\"]:\n",
    "        all_images, train_captions_mapping = load_images_flickr(train_dataset_configuration)\n",
    "    return all_images, train_captions_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3123463486_f5b36a3624': {'measures': {'Bleu_1'}, 'dataset_name': 'flickr8k', 'Bleu_1': 0.9999999998750002, 'Bleu_2': 0.8451542546153265, 'Bleu_3': 0.4919340733318464, 'Bleu_4': 6.985342055472009e-05, 'ROUGE_L': 0.7331730769230769, 'METEOR': 0.134383761300984, 'CIDEr': 0.9780245030146637, 'caption': 'a black dog is running on the sand', 'ground_truth_captions': ['A brown , black , and white dog runs along on the gravel .', 'A dog runs', 'A little dog running on sand .', 'The brown , white and black dog runs on a gravel surface .', 'The dog is running across the gravel .'], 'result_config_name': 'mixed_flickr8k_flickr8k_resnet50_glove.json', 'image_path': '/home2/data/images/flickr8k/Images/3123463486_f5b36a3624.jpg', 'is_best': False}, '3364026240_645d533fda': {'measures': {'Bleu_3', 'Bleu_2'}, 'dataset_name': 'flickr8k', 'Bleu_1': 0.9999999997500004, 'Bleu_2': 0.9258200995328305, 'Bleu_3': 0.8298265331423224, 'Bleu_4': 0.6914415690877681, 'ROUGE_L': 0.7724312590448625, 'METEOR': 0.12867307080544854, 'CIDEr': 1.1951849408757653, 'caption': 'a skier is skiing down a snowy mountain', 'ground_truth_captions': ['a lone skier skiing down a snowy mountain on one ski .', 'A man skis downhill on a mountain .', 'A mountain skier heads down a mountain .', 'A skier in a blue outfit is skiing down the hill with a red pack on his back .', 'A snowboarder on a wide plain of snow'], 'result_config_name': 'mixed_flickr8k_flickr8k_resnet50_glove.json', 'image_path': '/home2/data/images/flickr8k/Images/3364026240_645d533fda.jpg', 'is_best': False}, '3363750526_efcedc47a9': {'measures': {'Bleu_4', 'CIDEr'}, 'dataset_name': 'flickr8k', 'Bleu_1': 0.894839316615517, 'Bleu_2': 0.8370455347417358, 'Bleu_3': 0.8130154747365801, 'Bleu_4': 0.7956371659952094, 'ROUGE_L': 0.8698752228163993, 'METEOR': 0.26857775282065366, 'CIDEr': 3.411842559274331, 'caption': 'a black and white dog is running on sand', 'ground_truth_captions': ['A black and white dog is running on the beach .', 'A dog runs on the beach .', 'Black and white dog on wet sand .', 'The black and white dog is running in the damp sand .', 'This large black and white dog is running on the sand .'], 'result_config_name': 'mixed_flickr8k_flickr8k_resnet50_glove.json', 'image_path': '/home2/data/images/flickr8k/Images/3363750526_efcedc47a9.jpg', 'is_best': False}, '3461041826_0e24cdf597': {'measures': {'METEOR'}, 'dataset_name': 'flickr8k', 'Bleu_1': 0.6249999999218752, 'Bleu_2': 0.4225771273076633, 'Bleu_3': 3.0989904707566086e-06, 'Bleu_4': 8.783602618320611e-09, 'ROUGE_L': 0.5446428571428571, 'METEOR': 0.9304257528556595, 'CIDEr': 0.3037459267703056, 'caption': 'a black dog is swimming through a river', 'ground_truth_captions': ['A black and white dog is playing in a pond or creek .', 'A black and white dog is splashing around in the water .', 'A black and white dog is splashing in a stream .', 'A dog playing in some water .', 'A white dog is splashing in an outdoor stream next to a grassy bank .'], 'result_config_name': 'mixed_flickr8k_flickr8k_resnet50_glove.json', 'image_path': '/home2/data/images/flickr8k/Images/3461041826_0e24cdf597.jpg', 'is_best': False}, '3301859683_2d5e4b40a3': {'measures': {'ROUGE_L'}, 'dataset_name': 'flickr8k', 'Bleu_1': 0.8749999998906252, 'Bleu_2': 0.7905694149362151, 'Bleu_3': 0.6786044040504369, 'Bleu_4': 0.4999999999206847, 'ROUGE_L': 0.8798076923076923, 'METEOR': 0.1059544984087472, 'CIDEr': 1.4292098297960725, 'caption': 'a man is skiing down a snowy hill', 'ground_truth_captions': ['A man skiing down a hill .', 'A man skis down a snowy hill .', 'A person skis downhill .', 'a skier dressed in black speeds down the mountain .', 'Closeup of a skier with his poles out wide to the side .'], 'result_config_name': 'mixed_flickr8k_flickr8k_resnet50_glove.json', 'image_path': '/home2/data/images/flickr8k/Images/3301859683_2d5e4b40a3.jpg', 'is_best': False}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from config import general\n",
    "intersection=dict()\n",
    "max_set_of_ids=set()\n",
    "max_dict_of_ids=dict()\n",
    "min_dict_of_ids=dict()\n",
    "min_set_of_ids=set()\n",
    "\n",
    "bleu1_ids=list()\n",
    "bleu2_ids=list()\n",
    "bleu3_ids=list()\n",
    "bleu4_ids=list()\n",
    "cider_ids=list()\n",
    "meteor_ids=list()\n",
    "rouge_ids=list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sort_and_get_max_min(metric, name):\n",
    "    sorted_by=sorted(metric.items(), key=lambda x:x[1])\n",
    "\n",
    "    sorted_max_n=sorted_by[-1]\n",
    "    sorted_min_n=sorted_by[1]\n",
    "\n",
    "    image_id_min=sorted_min_n[0]\n",
    "    image_id_max=sorted_max_n[0]\n",
    "\n",
    "    min_set_of_ids.add(image_id_min)\n",
    "    if image_id_min not in min_dict_of_ids:\n",
    "        min_dict_of_ids[image_id_min]={\"measures\":{name},\n",
    "                                       \"dataset_name\":dataset_name,\n",
    "                                       \"Bleu_1\":results['imgToEval'][image_id_min]['Bleu_1'],\n",
    "                                       \"Bleu_2\":results['imgToEval'][image_id_min]['Bleu_2'],\n",
    "                                        \"Bleu_3\":results['imgToEval'][image_id_min]['Bleu_3'],\n",
    "                                        \"Bleu_4\":results['imgToEval'][image_id_min]['Bleu_4'],\n",
    "                                        \"ROUGE_L\":results['imgToEval'][image_id_min]['ROUGE_L'],\n",
    "                                        \"METEOR\":results['imgToEval'][image_id_min]['METEOR'],\n",
    "                                        \"CIDEr\":results['imgToEval'][image_id_min]['CIDEr'],\n",
    "                                       \"caption\":results['imgToEval'][image_id_min]['caption'],\n",
    "                                       \"ground_truth_captions\":results['imgToEval'][image_id_min]['ground_truth_captions'],\n",
    "                                       \"result_config_name\":result_config_name,\n",
    "                                       \"image_path\":all_images_from_split[image_id_min]}\n",
    "    else:\n",
    "        a=min_dict_of_ids[image_id_min][\"measures\"]\n",
    "        a.add(name)\n",
    "\n",
    "    max_set_of_ids.add(image_id_max)\n",
    "    if image_id_max not in max_dict_of_ids:\n",
    "        max_dict_of_ids[image_id_max]={\"measures\":{name},\n",
    "                                       \"dataset_name\":dataset_name,\n",
    "                                        \"Bleu_1\":results['imgToEval'][image_id_max]['Bleu_1'],\n",
    "                                       \"Bleu_2\":results['imgToEval'][image_id_max]['Bleu_2'],\n",
    "                                        \"Bleu_3\":results['imgToEval'][image_id_max]['Bleu_3'],\n",
    "                                        \"Bleu_4\":results['imgToEval'][image_id_max]['Bleu_4'],\n",
    "                                        \"ROUGE_L\":results['imgToEval'][image_id_max]['ROUGE_L'],\n",
    "                                        \"METEOR\":results['imgToEval'][image_id_max]['METEOR'],\n",
    "                                        \"CIDEr\":results['imgToEval'][image_id_max]['CIDEr'],\n",
    "                                       \"caption\":results['imgToEval'][image_id_max]['caption'],\n",
    "                                       \"ground_truth_captions\":results['imgToEval'][image_id_max]['ground_truth_captions'],\n",
    "                                       \"result_config_name\":result_config_name,\n",
    "                                       \"image_path\":all_images_from_split[image_id_max]}\n",
    "    else:\n",
    "        a=max_dict_of_ids[image_id_max][\"measures\"]\n",
    "        a.add(name)\n",
    "    return image_id_max, image_id_min, sorted_by\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for result_config_name in os.listdir(general[\"results_directory\"]):\n",
    "    if result_config_name.endswith(\".json\"):\n",
    "        results = json.load(open(\"./\" + general[\"results_directory\"] + \"/\" + result_config_name, 'r'))\n",
    "        dataset_name=results[\"dataset_name\"]\n",
    "\n",
    "        result_images_ids = list(results['imgToEval'].keys())\n",
    "        bleu1=dict()\n",
    "        bleu2=dict()\n",
    "        bleu3=dict()\n",
    "        bleu4=dict()\n",
    "        rouge=dict()\n",
    "        meteor=dict()\n",
    "        cider=dict()\n",
    "        for img_id in result_images_ids:\n",
    "            bleu1[img_id]=results['imgToEval'][img_id]['Bleu_1']\n",
    "            bleu2[img_id]=results['imgToEval'][img_id]['Bleu_2']\n",
    "            bleu3[img_id]=results['imgToEval'][img_id]['Bleu_3']\n",
    "            bleu4[img_id]=results['imgToEval'][img_id]['Bleu_4']\n",
    "            rouge[img_id]=results['imgToEval'][img_id]['ROUGE_L']\n",
    "            meteor[img_id]=results['imgToEval'][img_id]['METEOR']\n",
    "            cider[img_id]=results['imgToEval'][img_id]['CIDEr']\n",
    "\n",
    "\n",
    "        all_images_from_split, train_captions = get_images_for_split(dataset_name)\n",
    "        bleu1_sorted_max_n, bleu1_sorted_min_n, bleu1_sorted=sort_and_get_max_min(bleu1, \"Bleu_1\")\n",
    "        bleu2_sorted_max_n, bleu2_sorted_min_n, bleu2_sorted=sort_and_get_max_min(bleu2, \"Bleu_2\")\n",
    "        bleu3_sorted_max_n, bleu3_sorted_min_n, bleu3_sorted=sort_and_get_max_min(bleu3,'Bleu_3')\n",
    "        bleu4_sorted_max_n, bleu4_sorted_min_n, bleu4_sorted=sort_and_get_max_min(bleu4, 'Bleu_4')\n",
    "        meteor_sorted_max_n, meteor_sorted_min_n, meteor_sorted=sort_and_get_max_min(meteor,'METEOR')\n",
    "        rouge_sorted_max_n, rouge_sorted_min_n, rouge_sorted=sort_and_get_max_min(rouge, 'ROUGE_L')\n",
    "        cider_sorted_max_n, cider_sorted_min_n, cider_sorted=sort_and_get_max_min(cider, 'CIDEr')\n",
    "\n",
    "\n",
    "metrics=['Bleu_4', 'METEOR','ROUGE_L','CIDEr']\n",
    "for x in max_dict_of_ids.keys():\n",
    "    max_dict_of_ids[x][\"is_best\"]=all(item in max_dict_of_ids[x]['measures'] for item in metrics)\n",
    "for x in min_dict_of_ids.keys():\n",
    "    min_dict_of_ids[x][\"is_best\"]=all(item in min_dict_of_ids[x]['measures'] for item in metrics)\n",
    "\n",
    "print(max_dict_of_ids)\n",
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "with open(\"./\" + general[\"results_directory\"] +\"/intersection\"+ \"/intersection_results.json\", 'w') as outfile:\n",
    "    json.dump(\n",
    "        {\"max_dict_of_ids\":max_dict_of_ids,\n",
    "         \"min_dict_of_ids\":min_dict_of_ids},outfile, cls=SetEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(text, n=2, m=None, max_features=20000):\n",
    "    \n",
    "    vec = CountVectorizer(ngram_range = (n, n), \n",
    "                          max_features = max_features).fit(text)\n",
    "    bag_of_words = vec.transform(text)\n",
    "    sum_words = bag_of_words.sum(axis = 0)\n",
    "    words_freq = dict()\n",
    "    words_freq = {word: sum_words[0, i] for word, i in vec.vocabulary_.items()}\n",
    "    words_freq = {k: v for k, v in sorted(words_freq.items(), key=lambda item: item[1], reverse=True)}\n",
    "   \n",
    "    return words_freq\n",
    "\n",
    "def n_gram_train_captions(train_captions_dict, n=2):\n",
    "    #     train_captions = set()\n",
    "#     for val in train_captions_dict.values():\n",
    "#         for sentence in val:\n",
    "#             train_captions.add(sentence)\n",
    "\n",
    "    train_captions = list()\n",
    "    for val in train_captions_dict.values():\n",
    "        for sentence in val:\n",
    "            train_captions.append(sentence)\n",
    "    unigrams = get_ngrams(train_captions, n)\n",
    "    file = open(f'captions_n_gram/train_captions{n}', 'wb')\n",
    "    pickle.dump(unigrams, file)\n",
    "    file.close()\n",
    "#     vectorizer = CountVectorizer()\n",
    "#     X = vectorizer.fit_transform(train_captions)\n",
    "#     captions_words = vectorizer.get_feature_names()\n",
    "#     vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
    "#     X2 = vectorizer2.fit_transform(train_captions)\n",
    "#     captions_grams = vectorizer2.get_feature_names()\n",
    "#     print(vectorizer2.get_params())\n",
    "#     return captions_grams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_train_captions(train_captions,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czy dobrze jest policzona suma wszystkich n-gram√≥w, czy dobrze jest wyliczony procent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def n_gram_stat(n, cap):\n",
    "    \n",
    "    # open a file, where you stored the pickled data\n",
    "    with open(f'captions_n_gram/train_captions{n}', 'rb') as file:\n",
    "        all_captions_train = pickle.load(file)\n",
    "\n",
    "    \n",
    "    sum_all_cap = sum(all_captions_train.values())\n",
    "    caption = [cap]\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(caption)\n",
    "    captions_words = vectorizer.get_feature_names()\n",
    "    vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
    "    X2 = vectorizer2.fit_transform(caption)\n",
    "    captions_grams = vectorizer2.get_feature_names()\n",
    "    perc_gram = []\n",
    "    for cap_gram in captions_grams:\n",
    "\n",
    "        try:\n",
    "            perc_gram.append((cap_gram, all_captions_train[cap_gram]/sum_all_cap))\n",
    "        except KeyError as e:\n",
    "            perc_gram.append((cap_gram, 0))\n",
    "\n",
    "    return perc_gram\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_image_results_captions(image_id, intersection_results):\n",
    "    \"\"\"\n",
    "    Method to show image, ground truth captions, predicted caption and results of metrics\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_id: str\n",
    "        ID of image\n",
    "    Returns\n",
    "    -------\n",
    "    Prints image, ground truth captions, predicted caption and results of metrics\n",
    "    \"\"\"\n",
    "    #Load results of metrics from file\n",
    "    image_results = intersection_results[image_id]\n",
    "    print('Dataset name: {}'.format(image_results[\"dataset_name\"]))\n",
    "    #Load image\n",
    "    I = io.imread(image_results['image_path'])\n",
    "    plt.imshow(I)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"Ground truth captions\")\n",
    "    print(image_results['ground_truth_captions'])\n",
    "    print(\"Predicted captions\")\n",
    "    print(image_results['caption'])\n",
    "    print(n_gram_stat(2, image_results['caption']))\n",
    "    #Display results in pretty table\n",
    "    print( f'\\n===== Results =====' )\n",
    "#     print(image_results[\"metrics\"])\n",
    "#     print(image_results[\"is_best\"])\n",
    "    t = PrettyTable((\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"))\n",
    "    t.add_row((image_results[\"Bleu_1\"], image_results[\"Bleu_2\"], image_results[\"Bleu_3\"], image_results[\"Bleu_4\"]))\n",
    "    t2 = PrettyTable((\"METEOR\", \"ROUGE_L\", \"CIDEr\"))\n",
    "    t2.add_row((image_results[\"METEOR\"],image_results[\"ROUGE_L\"], image_results[\"CIDEr\"]))\n",
    "    print(t)\n",
    "    print(t2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#List all files from results directory to view data\n",
    "type_of_filter = [\"max_dict_of_ids\", \"min_dict_of_ids\"]\n",
    "selectbox = widgets.Select(\n",
    "    options=type_of_filter,\n",
    "    value=type_of_filter[1],\n",
    "    description='Min/max:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_dict_of_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abfd331cd74472aabc0f2275f1d6278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='<', style=ButtonStyle()), Button(description='>', style=ButtonStyle())))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7d8f728fa948fb98af4171618ca184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(selectbox.value)\n",
    "intersection_results = json.load(open(general[\"results_directory\"] + \"/intersection/intersection_results.json\"))\n",
    "inter_results=intersection_results[selectbox.value]\n",
    "images_ids=list(inter_results.keys())\n",
    "#Create fancy viever for images, captions and results of evaluation\n",
    "d=deque(images_ids)\n",
    "#Button to read image back\n",
    "left = Button(description=\"<\")\n",
    "#Button to read next image\n",
    "right = Button(description=\">\")\n",
    "\n",
    "switch = [left, right]\n",
    "\n",
    "combined = HBox([items for items in switch])\n",
    "out = Output()\n",
    "\n",
    "def on_button_left(ex):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        d.rotate(1)\n",
    "        show_image_results_captions(d[0], inter_results)\n",
    "def on_button_right(ex):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        d.rotate(-1)\n",
    "        show_image_results_captions(d[0], inter_results)\n",
    "l=switch[0].on_click(on_button_left)\n",
    "r=switch[1].on_click(on_button_right)\n",
    "display(combined)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framework",
   "language": "python",
   "name": "framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
